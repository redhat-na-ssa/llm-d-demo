# Notes

vllm Image as of 11/05/2025:

- `registry.redhat.io/rhaiis/vllm-cuda-rhel9@sha256:df300e32078427d779738bd919cc53aee772118246388f3ea8d529af0e8a85e9`

Create traditional route to distributed inference service

```sh
```

## Links

- [OAI / RHIIS VLLM Supported Models]()

## Issues

- The namespace `opendatahub` is installed

## TODO

- [x] Verify that gateway works on bare metal cluster
  - `MetalLB` operator / config was needed for bare metal
- [x] Create configuration for [GPT-OSS-20B](https://huggingface.co/openai/gpt-oss-20b)
